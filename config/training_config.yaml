# Training Configuration for Financial LLM Advisor

model:
  name: "microsoft/phi-3.5-mini-instruct"
  quantization: "8bit"
  trust_remote_code: true

dataset:
  name: "Josephgflowers/Finance-Instruct-500k"
  split_ratio:
    train: 0.8
    validation: 0.1
    test: 0.1
  subset_size: 50000
  max_seq_length: 1024
  filtering:
    min_length: 50
    max_length: 1000

training:
  num_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_steps: 500
  warmup_ratio: 0.0
  max_steps: -1
  logging_steps: 100
  eval_steps: 500
  save_steps: 500
  save_total_limit: 3
  gradient_checkpointing: true

lora:
  rank: 16
  alpha: 32
  dropout: 0.05
  target_modules: ["qkv_proj", "o_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"

generation:
  max_new_tokens: 1024
  temperature: 0.7
  top_p: 0.95
  top_k: 50
  repetition_penalty: 1.0
  do_sample: true

wandb:
  project: "financial-llm-advisor"
  entity: "your-wandb-username"
  enabled: false
  log_model: true

output_dir: "./checkpoints"
eval_strategy: "steps"
save_strategy: "steps"
logging_dir: "./logs"
seed: 42
fp16: false
bf16: true
optim: "adamw_8bit"